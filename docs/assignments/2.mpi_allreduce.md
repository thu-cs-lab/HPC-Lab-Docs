# 小作业二：MPI Allreduce

负责助教：师天麾 sth19@mails.tsinghua.edu.cn

## 背景

在课堂上，我们学习了 MPI 的集合通信原语和一些常见的算法实现。本次作业需要你实现 Ring Allreduce 算法。

## 任务

实验文件在集群上的位置为 `/home/course/hpc/assignments/2024/exp2` 。

首先将实验文件 **拷贝到自己的目录** ，并进入 `exp2` 目录：

```bash
cp -R /home/course/hpc/assignments/2024/exp2 ~/
cd ~/exp2/
```

在 `allreduce.cpp` 代码中，使用了 MPI_Allreduce 、MPI_Reduce + MPI_Bcast（在之后称为Naive_Allreduce） 和（待）手动实现的 Ring Allreduce 算法，并比较了三者的性能。使用以下方式编译程序：

```bash
spack load openmpi
mpicxx allreduce.cpp -O3 -std=c++11 -o allreduce
```

编译得到的 `allreduce` 程序有两个输入参数，分别代表 运行轮数和每个进程中需要进行 allreduce 的 float 个数。使用以下方式运行程序：

```bash
srun -N 4 -n 4 ./allreduce 10 100000000
```

在你实现自己的allreduce算法前，程序将会输出 `Wrong!`。你需要实现`allreduce.cpp`中的 `Ring_Allreduce` 函数。正确实现后，程序将输出如下结果：

```bash
Correct.
MPI_Allreduce:   XXXX ms.
Naive_Allreduce: XXXX ms. 
Ring_Allreduce:  XXXX ms.
```

注意，不同机器间的通信和同一台机器内部多进程间的通信性能不同（同一台机器内部使用内存拷贝）。传输消息量过小也可能导致性能波动。

### 任务：通信时间测试

选择不同进程数和不同通信量，测试 MPI_Allreduce，Naive_Allreduce 和你自己实现的 Ring_Allreduce 的运行时间。

你实现的 Ring Allreduce 算法 **比 MPI_Allreduce 快或慢** 都是正常现象。本作业旨在帮组大家熟悉集合通信算法的实现，并不过分追求性能。

## 实验提交

此实验仅需提交实验报告。

在报告中，你需要简述你所实现的 Ring Allreduce 算法，并提交你所测试的通信时间。除表格和图片外，建议文字内容不超过一页。

将报告的 **PDF 文件** 提交至网络学堂。

