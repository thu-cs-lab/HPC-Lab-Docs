# 小作业二：MPI Allreduce

负责助教：师天麾 sth19@mails.tsinghua.edu.cn

## 背景

在课堂上，我们学习了 MPI 的集合通信原语和一些常见的算法实现。本次作业需要你实现一种Allreduce算法（**推荐实现 Ring Allreduce 算法**）。

## 任务

实验文件在集群上的位置为 `/home/course/hpc/assignments/2022/exp2` 。

首先将实验文件 **拷贝到自己的目录** ，并进入 `exp2` 目录：

```bash
cp -R /home/course/hpc/assignments/2022/exp2 ~/
cd ~/exp2/
```

在 `allreduce.cpp` 代码中，使用了 MPI_Allreduce 和（待）手动实现的 allreduce 算法，并比较了两者的性能。使用以下方式编译程序：

```bash
spack load openmpi
mpicxx allreduce.cpp -O3 -std=c++11 -o allreduce
```

编译得到的 `allreduce` 程序有两个输入参数，分别代表 运行轮数和每个进程中需要进行 allreduce 的 float 个数。使用以下方式运行程序：

```bash
srun -N 4 -n 4 ./allreduce 10 100000000
```

在你实现自己的allreduce算法前，程序将会输出 `Wrong!`。你需要实现`allreduce.cpp`中的 `user_Allreduce` 函数。正确实现后，程序将输出如下结果：

```bash
Correct.
MPI_Allreduce:  XXXX ms.
user_Allreduce: XXXX ms.
```

注意，不同机器间的通信和同一台机器内部多进程间的通信性能不同（同一台机器内部使用内存拷贝）。传输消息量过小也可能导致性能波动。

### 任务：通信时间测试

选择不同进程数和不同通信量，测试 MPI_Allreduce 和你自己实现的 allreduce 的运行时间。

你实现的 allreduce 算法大概率会**比 MPI_Allreduce 慢**，这是正常现象。本作业旨在帮组大家熟悉集合通信算法的实现，并不过分追求性能。

## 实验提交

此实验仅需提交实验报告。

在报告中，你需要简述你所实现的 allreduce 算法，并提交你所测试的通信时间。除表格和图片外，建议文字内容不超过一页。

将报告的 **PDF 文件** 提交至网络学堂。