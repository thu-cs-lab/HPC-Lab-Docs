# 小作业四：CUDA 并行策略 (thread block, shared memory)

负责助教：黄可钊 hkz20@mails.tsinghua.edu.cn

## 背景

在课堂上，我们学习了在 CUDA 中如何通过设定 thread block 大小来改变 GPU 上的并行策略；同时我们也学习了使用 shared memory 来手动地 cache 和 reuse 数据。请在本次作业中需要：

1. 观察不同的 thread block 大小对性能的影响并分析原因；
2. 观察 shared memory 对性能的影响并分析原因。

## 任务

实验文件在集群上的位置为 `/home/course/hpc/assignments/2024/exp4`。

首先将实验文件 **拷贝到自己的目录** ，并进入 `exp4` 目录：

```bash
cp -R /home/course/hpc/assignments/2024/exp4 ~/
cd ~/exp4/
```

加载环境并编译 CUDA 代码

```bash
spack load cuda
make
srun --gpus 1 --exclusive ./run_cuda
```

程序完成的任务为：给定高宽为 `H+2` 和 `W+2` 的数组 `input`，对于其上每个点，计算它与它右边，下边，右下共计9个点计算后的和，得到高宽为 `H` 和 `W`的数组 `output`，计算如下图所示。

![illustration](./fig/exp6/cuda0-conv3x3.jpg)

本实验中，`test_func` 函数接受的四个参数分别为 `thread block size X`（X 维度上的 thread block 大小）,`thread block size Y`（Y 维度上的 thread block 大小）,`use_shared_mem`（是否使用 shared memory，默认为 false）,`validation`（是否校验结果，默认为 false）。

请测试：

1. 不同的 thread block size 的选取，对程序性能的影响；
2. Shared memory 是否使用，对程序性能的影响；
3. 上述两者的相互影响。

**请在报告中汇报你的测量结果，并简要分析其原因**。一些可以分析的点包括：

* 对于这个程序：
    * 如何设置 thread block size 才可以达到最好的效果？为什么？
    * Shared memory 总是带来优化吗？如果不是，为什么？
    * Shared memory 在什么 thread block size 下有效果，什么时候没有？
    * 还有哪些可以优化的地方？
* 对于任意一个给定程序：
    * 应该如何设置 thread block size？
    * 应该如何决定 shared memory 的使用？

## 实验提交

本实验仅需提交实验报告，请将报告的 **PDF 文件** 提交至网络学堂。
